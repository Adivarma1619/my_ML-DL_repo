{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c2626f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "00419ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('Sonar_dataset.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "1981091f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a4beb582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "593c017a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='60'>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[60].value_counts().plot(kind='bar', color=['blue', 'orange'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1ad7c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x= df.iloc[:, :-1]\n",
    "# y = df.iloc[:, -1]\n",
    "# x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a14e540f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      50      51      52      53      54      55      56  \\\n",
       "0  0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180   \n",
       "1  0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
       "2  0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n",
       "3  0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n",
       "4  0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n",
       "\n",
       "       57      58      59  \n",
       "0  0.0084  0.0090  0.0032  \n",
       "1  0.0049  0.0052  0.0044  \n",
       "2  0.0164  0.0095  0.0078  \n",
       "3  0.0044  0.0040  0.0117  \n",
       "4  0.0048  0.0107  0.0094  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.drop(columns=60)\n",
    "y = df[60]\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "7ae99d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.sample of      R\n",
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "..  ..\n",
       "203  0\n",
       "204  0\n",
       "205  0\n",
       "206  0\n",
       "207  0\n",
       "\n",
       "[208 rows x 1 columns]>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y, drop_first=True, dtype='int')\n",
    "y.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a42a3054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R\n",
       "0    111\n",
       "1     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAG7CAYAAADpF271AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGt5JREFUeJzt3X9sXXd9//HXbZM6SbENTVsbU7cYzRI/DCNNuojQkTCIy491sG6jXVg1tq4EXLqZdE2XdRuhEraSQohoRKYGqQ1jgf6xduu2biRiUggKiBDKtqYo0UZKPVIvbLXslLgOTe7+qHK/Xzf9lfY69+Pk8ZCO1HvO8c3bUk/uM597fF2pVqvVAAAU5KxGDwAA8EwCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOLMaPQAL8WxY8dy4MCBNDc3p1KpNHocAOBFqFarOXToUDo6OnLWWc+/RjItA+XAgQPp7Oxs9BgAwEswNDSUiy666HnPmZaB0tzcnOTpb7ClpaXB0wAAL8bY2Fg6Oztrr+PPZ1oGyvG3dVpaWgQKAEwzL+b2DDfJAgDFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQnBmNHoCTU6k0egJOpWq10RMANIYVFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgnHSjf/OY3c+WVV6ajoyOVSiV/+7d/O+l4tVrN6tWr09HRkdmzZ2fJkiXZs2fPpHMmJiZy44035vzzz8+5556bX/u1X8t//dd/vaxvBAA4fZx0oPzsZz/LL/7iL2bDhg3Penzt2rVZt25dNmzYkF27dqW9vT1Lly7NoUOHauf09/fnvvvuy9e+9rV861vfyhNPPJFf/dVfzdGjR1/6dwIAnDYq1Wq1+pK/uFLJfffdlw9+8INJnl496ejoSH9/f2655ZYkT6+WtLW1Zc2aNVm+fHlGR0dzwQUX5K/+6q9y9dVXJ0kOHDiQzs7OPPDAA7niiite8M8dGxtLa2trRkdH09LS8lLHn5YqlUZPwKn00q9OgPKczOt3Xe9B2b9/f4aHh9Pb21vb19TUlMWLF2fnzp1Jkt27d+fnP//5pHM6OjrS09NTO+eZJiYmMjY2NmkDAE5fdQ2U4eHhJElbW9uk/W1tbbVjw8PDOeecc/KqV73qOc95psHBwbS2tta2zs7Oeo4NABRmSn6Kp/KM9yGq1eoJ+57p+c5ZtWpVRkdHa9vQ0FDdZgUAylPXQGlvb0+SE1ZCDh48WFtVaW9vz5EjRzIyMvKc5zxTU1NTWlpaJm0AwOmrroHS1dWV9vb2bNu2rbbvyJEj2b59exYtWpQkmT9/fmbOnDnpnMceeywPPfRQ7RwA4Mw242S/4Iknnsh//Md/1B7v378/P/jBD3Leeefl4osvTn9/fwYGBtLd3Z3u7u4MDAxkzpw5WbZsWZKktbU11113XW666abMnTs35513Xv74j/84b37zm/Pud7+7ft8ZADBtnXSgfO9738s73/nO2uMVK1YkSX73d383d999d1auXJnx8fH09fVlZGQkCxcuzNatW9Pc3Fz7ms9//vOZMWNGPvShD2V8fDzvete7cvfdd+fss8+uw7cEAEx3L+tzUBrF56Bwpph+VyfAc2vY56AAANSDQAEAiiNQAIDinPRNsgBMkS1uMjujLHOT2fOxggIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFCcugfKU089lT/7sz9LV1dXZs+ende97nW57bbbcuzYsdo51Wo1q1evTkdHR2bPnp0lS5Zkz5499R4FAJim6h4oa9asyV/+5V9mw4YN+eEPf5i1a9fm9ttvzx133FE7Z+3atVm3bl02bNiQXbt2pb29PUuXLs2hQ4fqPQ4AMA3VPVC+/e1v5wMf+EDe//7357WvfW1+8zd/M729vfne976X5OnVk/Xr1+fWW2/NVVddlZ6enmzevDmHDx/Oli1b6j0OADAN1T1QLr/88nzjG9/Ivn37kiT/+q//mm9961t53/velyTZv39/hoeH09vbW/uapqamLF68ODt37qz3OADANDSj3k94yy23ZHR0NK9//etz9tln5+jRo/nMZz6T3/7t306SDA8PJ0na2tomfV1bW1t+/OMfP+tzTkxMZGJiovZ4bGys3mMDAAWp+wrKPffck6985SvZsmVLvv/972fz5s357Gc/m82bN086r1KpTHpcrVZP2Hfc4OBgWltba1tnZ2e9xwYAClL3QLn55pvzJ3/yJ7nmmmvy5je/Oddee20++clPZnBwMEnS3t6e5P+tpBx38ODBE1ZVjlu1alVGR0dr29DQUL3HBgAKUvdAOXz4cM46a/LTnn322bUfM+7q6kp7e3u2bdtWO37kyJFs3749ixYtetbnbGpqSktLy6QNADh91f0elCuvvDKf+cxncvHFF+dNb3pTHnzwwaxbty6///u/n+Tpt3b6+/szMDCQ7u7udHd3Z2BgIHPmzMmyZcvqPQ4AMA3VPVDuuOOO/Pmf/3n6+vpy8ODBdHR0ZPny5fmLv/iL2jkrV67M+Ph4+vr6MjIykoULF2br1q1pbm6u9zgAwDRUqVar1UYPcbLGxsbS2tqa0dHRM+7tnue4j5jT1PS7OnlZtrjAzyjLzrwL/GRev/0uHgCgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDhTEig/+clP8ju/8zuZO3du5syZk7e+9a3ZvXt37Xi1Ws3q1avT0dGR2bNnZ8mSJdmzZ89UjAIATEN1D5SRkZG8/e1vz8yZM/NP//RPefjhh/O5z30ur3zlK2vnrF27NuvWrcuGDRuya9eutLe3Z+nSpTl06FC9xwEApqEZ9X7CNWvWpLOzM3fddVdt32tf+9raf1er1axfvz633nprrrrqqiTJ5s2b09bWli1btmT58uX1HgkAmGbqvoJy//33Z8GCBfmt3/qtXHjhhZk3b142bdpUO75///4MDw+nt7e3tq+pqSmLFy/Ozp07n/U5JyYmMjY2NmkDAE5fdQ+UH/3oR9m4cWO6u7vz9a9/PR/72Mfyh3/4h/nyl7+cJBkeHk6StLW1Tfq6tra22rFnGhwcTGtra23r7Oys99gAQEHqHijHjh3LpZdemoGBgcybNy/Lly/P9ddfn40bN046r1KpTHpcrVZP2HfcqlWrMjo6WtuGhobqPTYAUJC6B8qrX/3qvPGNb5y07w1veEMeffTRJEl7e3uSnLBacvDgwRNWVY5rampKS0vLpA0AOH3VPVDe/va3Z+/evZP27du3L5dcckmSpKurK+3t7dm2bVvt+JEjR7J9+/YsWrSo3uMAANNQ3X+K55Of/GQWLVqUgYGBfOhDH8p3v/vd3HnnnbnzzjuTPP3WTn9/fwYGBtLd3Z3u7u4MDAxkzpw5WbZsWb3HAQCmoboHymWXXZb77rsvq1atym233Zaurq6sX78+H/7wh2vnrFy5MuPj4+nr68vIyEgWLlyYrVu3prm5ud7jAADTUKVarVYbPcTJGhsbS2tra0ZHR8+4+1Ge4z5iTlPT7+rkZdniAj+jLDvzLvCTef32u3gAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAijPlgTI4OJhKpZL+/v7avmq1mtWrV6ejoyOzZ8/OkiVLsmfPnqkeBQCYJqY0UHbt2pU777wzb3nLWybtX7t2bdatW5cNGzZk165daW9vz9KlS3Po0KGpHAcAmCamLFCeeOKJfPjDH86mTZvyqle9qra/Wq1m/fr1ufXWW3PVVVelp6cnmzdvzuHDh7Nly5apGgcAmEamLFBuuOGGvP/978+73/3uSfv379+f4eHh9Pb21vY1NTVl8eLF2blz51SNAwBMIzOm4km/9rWv5fvf/3527dp1wrHh4eEkSVtb26T9bW1t+fGPf/yszzcxMZGJiYna47GxsTpOCwCUpu4rKENDQ/mjP/qjfOUrX8msWbOe87xKpTLpcbVaPWHfcYODg2ltba1tnZ2ddZ0ZAChL3QNl9+7dOXjwYObPn58ZM2ZkxowZ2b59e77whS9kxowZtZWT4yspxx08ePCEVZXjVq1aldHR0do2NDRU77EBgILU/S2ed73rXfn3f//3Sft+7/d+L69//etzyy235HWve13a29uzbdu2zJs3L0ly5MiRbN++PWvWrHnW52xqakpTU1O9RwUAClX3QGlubk5PT8+kfeeee27mzp1b29/f35+BgYF0d3enu7s7AwMDmTNnTpYtW1bvcQCAaWhKbpJ9IStXrsz4+Hj6+voyMjKShQsXZuvWrWlubm7EOABAYSrVarXa6CFO1tjYWFpbWzM6OpqWlpZGj3NKPcd9xJympt/VycuyxQV+Rll25l3gJ/P67XfxAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxal7oAwODuayyy5Lc3NzLrzwwnzwgx/M3r17J51TrVazevXqdHR0ZPbs2VmyZEn27NlT71EAgGmq7oGyffv23HDDDfnOd76Tbdu25amnnkpvb29+9rOf1c5Zu3Zt1q1blw0bNmTXrl1pb2/P0qVLc+jQoXqPAwBMQ5VqtVqdyj/gpz/9aS688MJs374973jHO1KtVtPR0ZH+/v7ccsstSZKJiYm0tbVlzZo1Wb58+Qs+59jYWFpbWzM6OpqWlpapHL84lUqjJ+BUmtqrk+JscYGfUZadeRf4ybx+T/k9KKOjo0mS8847L0myf//+DA8Pp7e3t3ZOU1NTFi9enJ07dz7rc0xMTGRsbGzSBgCcvqY0UKrValasWJHLL788PT09SZLh4eEkSVtb26Rz29raaseeaXBwMK2trbWts7NzKscGABpsSgPlE5/4RP7t3/4tX/3qV084VnnGexXVavWEfcetWrUqo6OjtW1oaGhK5gUAyjBjqp74xhtvzP33359vfvObueiii2r729vbkzy9kvLqV7+6tv/gwYMnrKoc19TUlKampqkaFQAoTN1XUKrVaj7xiU/k3nvvzb/8y7+kq6tr0vGurq60t7dn27ZttX1HjhzJ9u3bs2jRonqPAwBMQ3VfQbnhhhuyZcuW/N3f/V2am5tr95W0trZm9uzZqVQq6e/vz8DAQLq7u9Pd3Z2BgYHMmTMny5Ytq/c4AMA0VPdA2bhxY5JkyZIlk/bfdddd+chHPpIkWblyZcbHx9PX15eRkZEsXLgwW7duTXNzc73HAQCmoSn/HJSp4HNQOFNMv6uTl8XnoJxZfA7K857rd/EAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFKehgfLFL34xXV1dmTVrVubPn58dO3Y0chwAoBANC5R77rkn/f39ufXWW/Pggw/ml3/5l/Pe9743jz76aKNGAgAK0bBAWbduXa677rr8wR/8Qd7whjdk/fr16ezszMaNGxs1EgBQiIYEypEjR7J79+709vZO2t/b25udO3c2YiQAoCAzGvGH/s///E+OHj2atra2Sfvb2toyPDx8wvkTExOZmJioPR4dHU2SjI2NTe2g0GD+Fz/DHG70AJxSZ+AFfvx1u1qtvuC5DQmU4yqVyqTH1Wr1hH1JMjg4mE9/+tMn7O/s7Jyy2aAEra2NngCYMtefuRf4oUOH0voCf8E1JFDOP//8nH322Seslhw8ePCEVZUkWbVqVVasWFF7fOzYsTz++OOZO3fuswYNp5exsbF0dnZmaGgoLS0tjR4HqCPX95mlWq3m0KFD6ejoeMFzGxIo55xzTubPn59t27bl13/912v7t23blg984AMnnN/U1JSmpqZJ+175yldO9ZgUpqWlxV9gcJpyfZ85Xmjl5LiGvcWzYsWKXHvttVmwYEHe9ra35c4778yjjz6aj33sY40aCQAoRMMC5eqrr87//u//5rbbbstjjz2Wnp6ePPDAA7nkkksaNRIAUIiG3iTb19eXvr6+Ro7ANNDU1JRPfepTJ7zNB0x/rm+eS6X6Yn7WBwDgFPLLAgGA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOA39HBR4Lnv37s1Xv/rV7NixI4888kgOHz6cCy64IPPmzcsVV1yR3/iN3/C5CTBNub55MXwOCkV58MEHs3LlyuzYsSOLFi3KL/3SL+U1r3lNZs+enccffzwPPfRQduzYkbGxsaxcuTL9/f3+IoNpwvXNyRAoFOWSSy7JzTffnGXLluW88857zvO+/e1v5/Of/3ze+ta35k//9E9P4YTAS+X65mQIFIpy5MiRnHPOOVN2PtA4rm9OhkABAIrjp3iYlr785S/nP//zPxs9BjAFXN8kVlCYps4666zMnDkzH/3oR3PHHXc0ehygjlzfJFZQmKaOHTuWvXv3pqenp9GjAHXm+iaxggIAFMgHtVGsJ554Irt3787w8HAqlUra2toyf/78vOIVr2j0aMAUeeqpp3LgwIFcfPHFjR6FBhMoFOepp57KTTfdlE2bNuXJJ5/MOeeck2q1mp///OeZNWtWPvrRj+b222/PzJkzGz0qUGd79uzJpZdemqNHjzZ6FBrMPSgU56abbsrf/M3f5K677srjjz+eJ598MhMTE3n88cdz11135d57783NN9/c6DEBmELuQaE4F1xwQe655578yq/8yrMe/8Y3vpFrrrkmP/3pT0/xZMDLdemllz7v8fHx8ezbt88KCt7ioTzj4+M5//zzn/P43LlzMz4+fgonAurl4YcfzjXXXJOurq5nPf7YY49l3759p3gqSmQFheJceeWVGR8fz1//9V+nra1t0rH//u//zrXXXptZs2bl/vvvb9CEwEu1YMGCXHfddfn4xz/+rMd/8IMfZP78+VZQsIJCeb74xS/mfe97Xy666KL09PSkra0tlUolw8PDeeihh/LGN74x//iP/9joMYGX4PLLL8/evXuf83hzc3Pe8Y53nMKJKJUVFIp07NixfP3rX893vvOdDA8PJ0na29vztre9Lb29vTnrLPd3A5zOBApFefTRR0/q8w9+8pOf5DWvec0UTgTUi+ubk+GfoRTlsssuy/XXX5/vfve7z3nO6OhoNm3alJ6entx7772ncDrg5XB9czLcg0JRfvjDH2ZgYCDvec97MnPmzCxYsCAdHR2ZNWtWRkZG8vDDD2fPnj1ZsGBBbr/99rz3ve9t9MjAi+T65mR4i4ciPfnkk3nggQeyY8eOPPLII7UfPZ43b16uuOIKv0QMpjHXNy+GQAEAiuMeFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBSjCRz7ykVQqlVQqlcyYMSMXX3xxPv7xj2dkZKTRowENIFCAYrznPe/JY489lkceeSRf+tKX8vd///fp6+tr9FhAA/gkWaAYTU1NaW9vT5JcdNFFufrqq3P33Xc3diigIaygAEX60Y9+lH/+53/OzJkzGz0K0ABWUIBi/MM//ENe8YpX5OjRo3nyySeTJOvWrWvwVEAjCBSgGO985zuzcePGHD58OF/60peyb9++3HjjjY0eC2gAb/EAxTj33HPzC7/wC3nLW96SL3zhC5mYmMinP/3pRo8FNIBAAYr1qU99Kp/97Gdz4MCBRo8CnGICBSjWkiVL8qY3vSkDAwONHgU4xQQKULQVK1Zk06ZNGRoaavQowClUqVar1UYPAQDw/7OCAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUJz/A1Ci8AuqnRjZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.value_counts().plot(kind='bar', color=['blue', 'orange'])\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b40cad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4be0109e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156, 60), (52, 60), (156, 1), (52, 1))"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "cc6e5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "14ea2738",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(60, activation='relu', input_shape=(60,)),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1d2fef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5705 - loss: 0.6884\n",
      "Epoch 2/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5962 - loss: 0.6624 \n",
      "Epoch 3/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6987 - loss: 0.6437 \n",
      "Epoch 4/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6987 - loss: 0.6167 \n",
      "Epoch 5/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: 0.5935 \n",
      "Epoch 6/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6731 - loss: 0.5780\n",
      "Epoch 7/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.5199 \n",
      "Epoch 8/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.4981 \n",
      "Epoch 9/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7821 - loss: 0.4799 \n",
      "Epoch 10/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.4518 \n",
      "Epoch 11/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.4102\n",
      "Epoch 12/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.4098 \n",
      "Epoch 13/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8526 - loss: 0.3825 \n",
      "Epoch 14/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3640 \n",
      "Epoch 15/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3573 \n",
      "Epoch 16/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.3469\n",
      "Epoch 17/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3593 \n",
      "Epoch 18/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8910 - loss: 0.3059 \n",
      "Epoch 19/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8590 - loss: 0.3020\n",
      "Epoch 20/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8974 - loss: 0.2915 \n",
      "Epoch 21/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8910 - loss: 0.2671 \n",
      "Epoch 22/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.2570 \n",
      "Epoch 23/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9038 - loss: 0.2500 \n",
      "Epoch 24/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.2359 \n",
      "Epoch 25/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.2104 \n",
      "Epoch 26/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.1968 \n",
      "Epoch 27/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.1860 \n",
      "Epoch 28/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9359 - loss: 0.1732\n",
      "Epoch 29/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.1687 \n",
      "Epoch 30/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.1711 \n",
      "Epoch 31/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1485 \n",
      "Epoch 32/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1494\n",
      "Epoch 33/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.1450 \n",
      "Epoch 34/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9551 - loss: 0.1305 \n",
      "Epoch 35/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1327 \n",
      "Epoch 36/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.1078 \n",
      "Epoch 37/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0888  \n",
      "Epoch 38/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0834 \n",
      "Epoch 39/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9679 - loss: 0.0878 \n",
      "Epoch 40/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0781 \n",
      "Epoch 41/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0792 \n",
      "Epoch 42/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0608 \n",
      "Epoch 43/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0567 \n",
      "Epoch 44/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9872 - loss: 0.0618 \n",
      "Epoch 45/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0428 \n",
      "Epoch 46/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0529 \n",
      "Epoch 47/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0384 \n",
      "Epoch 48/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0368 \n",
      "Epoch 49/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0303 \n",
      "Epoch 50/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0282 \n",
      "Epoch 51/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0250 \n",
      "Epoch 52/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0225 \n",
      "Epoch 53/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0183\n",
      "Epoch 54/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0309 \n",
      "Epoch 55/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0256\n",
      "Epoch 56/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0257\n",
      "Epoch 57/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0203 \n",
      "Epoch 58/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0145 \n",
      "Epoch 59/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0113   \n",
      "Epoch 60/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0110 \n",
      "Epoch 61/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0095 \n",
      "Epoch 62/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0090     \n",
      "Epoch 63/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0082 \n",
      "Epoch 64/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0089 \n",
      "Epoch 65/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0073 \n",
      "Epoch 66/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0070 \n",
      "Epoch 67/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0063 \n",
      "Epoch 68/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0058 \n",
      "Epoch 69/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0057 \n",
      "Epoch 70/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0057 \n",
      "Epoch 71/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 72/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 73/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 74/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0043 \n",
      "Epoch 75/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 76/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0039     \n",
      "Epoch 77/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 78/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 79/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0031     \n",
      "Epoch 80/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 81/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 82/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 83/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 84/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 85/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0023  \n",
      "Epoch 86/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0022 \n",
      "Epoch 87/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 88/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 89/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0021     \n",
      "Epoch 90/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0018     \n",
      "Epoch 91/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0017 \n",
      "Epoch 92/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "Epoch 93/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0017 \n",
      "Epoch 94/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015     \n",
      "Epoch 95/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0016     \n",
      "Epoch 96/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014 \n",
      "Epoch 97/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014 \n",
      "Epoch 98/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 99/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012 \n",
      "Epoch 100/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a644276cd0>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "cf3fdbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8462 - loss: 0.4132 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41316574811935425, 0.8461538553237915]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "4a90165a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "[0 1 1 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0\n",
      " 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test).reshape(-1)\n",
    "y_pred = np.where(y_pred>0.5, 1, 0)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c0aa59a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R\n",
       "161  0\n",
       "15   1\n",
       "73   1\n",
       "96   1\n",
       "166  0\n",
       "9    1\n",
       "100  0\n",
       "135  0\n",
       "18   1\n",
       "148  0"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1135297c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86        30\n",
      "           1       0.79      0.86      0.83        22\n",
      "\n",
      "    accuracy                           0.85        52\n",
      "   macro avg       0.84      0.85      0.84        52\n",
      "weighted avg       0.85      0.85      0.85        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "2c15a7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5192 - loss: 0.7072\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5128 - loss: 0.6966 \n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5192 - loss: 0.7027 \n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4808 - loss: 0.6972 \n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5064 - loss: 0.6907 \n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4936 - loss: 0.6981 \n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5897 - loss: 0.6819 \n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5256 - loss: 0.6780 \n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5577 - loss: 0.6811 \n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5705 - loss: 0.6778 \n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5513 - loss: 0.6679 \n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5321 - loss: 0.6941 \n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5897 - loss: 0.6588 \n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6346 - loss: 0.6733 \n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5385 - loss: 0.6762 \n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5897 - loss: 0.6714 \n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6859 - loss: 0.6449 \n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5513 - loss: 0.6758 \n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5449 - loss: 0.6730 \n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6282 - loss: 0.6486 \n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6282 - loss: 0.6440 \n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6346 - loss: 0.6266 \n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6410 - loss: 0.6324 \n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6026 - loss: 0.6579 \n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: 0.6088 \n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7179 - loss: 0.6169 \n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6731 - loss: 0.6201 \n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6538 - loss: 0.6526 \n",
      "Epoch 29/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6795 - loss: 0.5926 \n",
      "Epoch 30/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6795 - loss: 0.6019 \n",
      "Epoch 31/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7115 - loss: 0.5990 \n",
      "Epoch 32/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7308 - loss: 0.5741 \n",
      "Epoch 33/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6346 - loss: 0.5945 \n",
      "Epoch 34/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7308 - loss: 0.5494 \n",
      "Epoch 35/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7115 - loss: 0.5827 \n",
      "Epoch 36/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7436 - loss: 0.5408 \n",
      "Epoch 37/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7051 - loss: 0.5714 \n",
      "Epoch 38/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7756 - loss: 0.5197 \n",
      "Epoch 39/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7308 - loss: 0.4991 \n",
      "Epoch 40/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7821 - loss: 0.5533\n",
      "Epoch 41/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7179 - loss: 0.5290 \n",
      "Epoch 42/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7500 - loss: 0.5031 \n",
      "Epoch 43/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7436 - loss: 0.5506 \n",
      "Epoch 44/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7821 - loss: 0.5113 \n",
      "Epoch 45/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7692 - loss: 0.4958 \n",
      "Epoch 46/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7308 - loss: 0.5112 \n",
      "Epoch 47/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7308 - loss: 0.4998 \n",
      "Epoch 48/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7628 - loss: 0.4810 \n",
      "Epoch 49/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7628 - loss: 0.4851 \n",
      "Epoch 50/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7885 - loss: 0.4432 \n",
      "Epoch 51/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8141 - loss: 0.4147 \n",
      "Epoch 52/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7692 - loss: 0.4699 \n",
      "Epoch 53/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8526 - loss: 0.4023\n",
      "Epoch 54/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.4898\n",
      "Epoch 55/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7949 - loss: 0.4204\n",
      "Epoch 56/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7821 - loss: 0.4441\n",
      "Epoch 57/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8141 - loss: 0.4252\n",
      "Epoch 58/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7756 - loss: 0.4835\n",
      "Epoch 59/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.3953  \n",
      "Epoch 60/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8141 - loss: 0.4456\n",
      "Epoch 61/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8269 - loss: 0.4305\n",
      "Epoch 62/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8205 - loss: 0.4093\n",
      "Epoch 63/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8205 - loss: 0.4001 \n",
      "Epoch 64/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8269 - loss: 0.4149 \n",
      "Epoch 65/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8462 - loss: 0.3907 \n",
      "Epoch 66/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.3773 \n",
      "Epoch 67/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.4302 \n",
      "Epoch 68/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8077 - loss: 0.4079 \n",
      "Epoch 69/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.3946 \n",
      "Epoch 70/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8397 - loss: 0.3835 \n",
      "Epoch 71/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8718 - loss: 0.3344 \n",
      "Epoch 72/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8397 - loss: 0.3443 \n",
      "Epoch 73/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8141 - loss: 0.3632\n",
      "Epoch 74/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8462 - loss: 0.3810 \n",
      "Epoch 75/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.3555 \n",
      "Epoch 76/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8269 - loss: 0.3670 \n",
      "Epoch 77/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8205 - loss: 0.3703 \n",
      "Epoch 78/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8397 - loss: 0.3375 \n",
      "Epoch 79/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8654 - loss: 0.3531 \n",
      "Epoch 80/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.2648 \n",
      "Epoch 81/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3748 \n",
      "Epoch 82/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.3164 \n",
      "Epoch 83/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.3269 \n",
      "Epoch 84/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3315 \n",
      "Epoch 85/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3222 \n",
      "Epoch 86/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3385 \n",
      "Epoch 87/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3261 \n",
      "Epoch 88/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.2582 \n",
      "Epoch 89/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.3074 \n",
      "Epoch 90/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.2911 \n",
      "Epoch 91/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8782 - loss: 0.2973 \n",
      "Epoch 92/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8782 - loss: 0.3121 \n",
      "Epoch 93/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8526 - loss: 0.3131\n",
      "Epoch 94/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9103 - loss: 0.2293 \n",
      "Epoch 95/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8654 - loss: 0.3109 \n",
      "Epoch 96/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.2793 \n",
      "Epoch 97/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8910 - loss: 0.2734 \n",
      "Epoch 98/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.2447 \n",
      "Epoch 99/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8590 - loss: 0.3254 \n",
      "Epoch 100/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8846 - loss: 0.2686 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a6444d9cc0>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = keras.Sequential([\n",
    "    keras.layers.Dense(60, activation='relu', input_shape=(60,)),\n",
    "    keras.layers.Dropout(0.5),  # Dropout layer with 20% dropout rate\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),  # Another Dropout layer\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),  # Another Dropout layer\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])   \n",
    "model1.fit(x_train, y_train, epochs=100, batch_size=9)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "3a31af06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9231 - loss: 0.2153 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21533767879009247, 0.9230769276618958]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "48612f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        30\n",
      "           1       0.91      0.91      0.91        22\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.92      0.92      0.92        52\n",
      "weighted avg       0.92      0.92      0.92        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = model1.predict(x_test).reshape(-1)\n",
    "y_pred1 = np.where(y_pred1>0.5, 1, 0)\n",
    "print(classification_report(y_test, y_pred1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
